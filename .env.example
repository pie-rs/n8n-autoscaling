## Environment Configuration
# Environment type affects database and user naming
# Options: dev, test, production
ENVIRONMENT=dev

## Documentation Links
# Main documentation
DOCS_README=https://github.com/conor-is-my-name/n8n-autoscaling/blob/main/README.md
#DOCS_CLAUDE=https://github.com/conor-is-my-name/n8n-autoscaling/blob/main/CLAUDE.md
#DOCS_N8N=https://docs.n8n.io/
#DOCS_REDDIT_GUIDE=https://www.reddit.com/r/n8n/comments/1l9mi6k/major_update_to_n8nautoscaling_build_step_by_step/

## Autoscaling Configuration
# Core project settings
COMPOSE_PROJECT_NAME=n8n-autoscaling
COMPOSE_FILE_PATH=/app/docker-compose.yml
GENERIC_TIMEZONE=America/New_York

# Worker scaling limits
MIN_REPLICAS=1                    # Minimum worker containers (never scale below this)
MAX_REPLICAS=5                    # Maximum worker containers (never scale above this)

# Scaling triggers (queue length thresholds)
SCALE_UP_QUEUE_THRESHOLD=5        # Scale up when queue length exceeds this number
SCALE_DOWN_QUEUE_THRESHOLD=1      # Scale down when queue length drops below this number

# Timing controls
POLLING_INTERVAL_SECONDS=10       # How often autoscaler checks queue length (default: 10s)
COOLDOWN_PERIOD_SECONDS=10        # Wait time between scaling actions to prevent flapping (default: 10s)
POLL_INTERVAL_SECONDS=5           # Monitor polling interval (default: 5s)

# Graceful shutdown settings
N8N_QUEUE_BULL_GRACEFULSHUTDOWNTIMEOUT=300  # Time to wait for running workflows to complete (300s = 5min)
N8N_GRACEFUL_SHUTDOWN_TIMEOUT=300           # Container shutdown timeout (should match above)

## Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=YOURREDISPASSWORD # Change this to a strong password
QUEUE_NAME_PREFIX=bull
QUEUE_NAME=jobs
QUEUE_BULL_REDIS_HOST=redis
QUEUE_HEALTH_CHECK_ACTIVE=true

## Postgres
POSTGRES_HOST=postgres
POSTGRES_DB=n8n_${ENVIRONMENT}              # Database name based on environment (n8n_dev, n8n_test, n8n_production)
POSTGRES_USER=n8n_${ENVIRONMENT}_user       # User name based on environment (n8n_dev_user, etc.)
POSTGRES_PASSWORD=YOURPASSWORD               # Change this to a strong password
POSTGRES_ADMIN_USER=postgres                 # PostgreSQL admin user for database/user creation
POSTGRES_ADMIN_PASSWORD=YOURADMINPASSWORD    # Admin password - change this too
PGDATA=/var/lib/postgresql/data/pgdata
DB_TYPE=postgresdb

## N8N
N8N_HOST=n8n.domain.com # Change this
N8N_WEBHOOK=webhook.domain.com # Change this
N8N_WEBHOOK_URL=https://webhook.domain.com # Change this
WEBHOOK_URL=https://webhook.domain.com # Change this
N8N_EDITOR_BASE_URL=https://n8n.domain.com # Change this
N8N_PROTOCOL=https
N8N_PORT=5678
N8N_DIAGNOSTICS_ENABLED=false
N8N_USER_FOLDER=/n8n/main
N8N_SECURE_COOKIE=true  # Enable secure cookies for HTTPS
N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=false
N8N_ENCRYPTION_KEY=YOURKEY # 32 characters MAKE YOUR OWN KEY (also used for backup encryption)
N8N_USER_MANAGEMENT_JWT_SECRET=YOURKEY # Change this to a strong password
N8N_WORKER_SERVICE_NAME=n8n-worker
EXECUTIONS_MODE=queue
OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS=true
N8N_TASK_BROKER_URL=http://n8n:5679
N8N_COMMAND_RESPONSE_URL=http://n8n:5679
N8N_TASK_BROKER_PORT=5679
N8N_RUNNERS_AUTH_TOKEN=YOURPASSWORD # Change this to a strong password
NODE_FUNCTION_ALLOW_EXTERNAL=ajv,ajv-formats,puppeteer,ffmpeg,git,graphicsmagick,openssh-client
PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium

## Cloudflare Tunnel
# Get your tunnel token from: https://dash.cloudflare.com/ → Zero Trust → Access → Tunnels
CLOUDFLARE_TUNNEL_TOKEN=your_tunnel_token_here

## Tailscale
TAILSCALE_IP= 
# Change this to your Tailscale IP OPTIONAL BUT RECOMMENDED

## Data Directories
# Local data directories (relative to project root)
DATA_DIR=./Data
LOGS_DIR=./Logs
BACKUPS_DIR=./backups

# Specific service data directories
POSTGRES_DATA_DIR=${DATA_DIR}/Postgres
REDIS_DATA_DIR=${DATA_DIR}/Redis
N8N_DATA_DIR=${DATA_DIR}/n8n
N8N_WEBHOOK_DATA_DIR=${DATA_DIR}/n8n-webhook
TRAEFIK_DATA_DIR=${DATA_DIR}/Traefik

# Rclone mount points (uncomment and configure if needed)
# Supports any rclone backend: Google Drive, OneDrive, S3, Dropbox, etc.
#RCLONE_DATA_MOUNT=/mnt/rclone-data
#RCLONE_BACKUP_MOUNT=/mnt/rclone-backups

# Logging Configuration
LOG_DRIVER=json-file
LOG_MAX_SIZE=10m
LOG_MAX_FILE=3

# Container Runtime Configuration (will automatically detect if not set)
# Override container runtime detection if needed (docker, podman)
#CONTAINER_RUNTIME_OVERRIDE=podman

# External Network Configuration
# Uncomment to enable external network for connecting to other containers
#EXTERNAL_NETWORK_NAME=n8n-external

## Systemd Service Configuration
# To create systemd service files, run: ./generate-systemd.sh
# This will create service files for automatic startup and management

# Podman auto-update configuration
# Set to "registry" to enable auto-updates, "no" to disable
PODMAN_AUTOUPDATE=registry

#############################################
#############################################
## Advanced Performance Tuning

# Uncomment and adjust these variables based on your system resources and workload requirements.
# Start with defaults and monitor performance before making changes.

# N8N Performance Variables
# Controls how many workflows each worker can execute concurrently
#N8N_CONCURRENCY_PRODUCTION_LIMIT=10       # Default: 10, increase for more parallel workflows (4-20 typical range)

# Execution data management to prevent database bloat
#N8N_EXECUTIONS_DATA_PRUNE=true            # Default: true, automatically clean old execution data
#N8N_EXECUTIONS_DATA_MAX_AGE=336           # Default: 336 hours (14 days), older executions are deleted
#N8N_EXECUTIONS_DATA_PRUNE_MAX_COUNT=10000 # Default: 10000, maximum executions to keep regardless of age

# Logging and monitoring
#N8N_LOG_LEVEL=info                        # Default: info, options: error, warn, info, debug, verbose, silly
#N8N_LOG_OUTPUT=console                    # Default: console, options: console, file
#N8N_METRICS=false                         # Default: false, enable Prometheus metrics endpoint
#N8N_SKIP_WEBHOOK_DEREGISTRATION_SHUTDOWN=true  # Default: true, faster shutdown for production

# Node.js runtime optimizations
#NODE_OPTIONS=--max-old-space-size=4096    # Default: 4096MB, increase for memory-intensive workflows
#UV_THREADPOOL_SIZE=16                     # Default: 16, increase for high I/O workloads (4-128 range)

# PostgreSQL Performance Variables
# Memory allocation (should be ~25% of system RAM for dedicated DB server)
#POSTGRES_SHARED_BUFFERS=256MB             # Default: 256MB, primary cache (128MB-8GB typical)
#POSTGRES_EFFECTIVE_CACHE_SIZE=1GB         # Default: 1GB, total memory available for caching (system RAM - other processes)
#POSTGRES_WORK_MEM=4MB                     # Default: 4MB, memory per query operation (1MB-1GB per connection)
#POSTGRES_MAINTENANCE_WORK_MEM=64MB        # Default: 64MB, memory for maintenance operations (16MB-2GB)

# Query performance
#POSTGRES_CHECKPOINT_COMPLETION_TARGET=0.9 # Default: 0.9, spread checkpoint I/O over time (0.5-0.9)
#POSTGRES_WAL_BUFFERS=16MB                 # Default: 16MB, write-ahead log buffer (3% of shared_buffers)
#POSTGRES_DEFAULT_STATISTICS_TARGET=100    # Default: 100, statistics depth for query planner (10-10000)
#POSTGRES_RANDOM_PAGE_COST=1.1             # Default: 1.1, cost of random page access (1.0 for SSD, 4.0 for HDD)
#POSTGRES_EFFECTIVE_IO_CONCURRENCY=200     # Default: 200, concurrent disk I/O (1 for HDD, 200+ for SSD)

# Parallel processing (adjust based on CPU cores)
#POSTGRES_MAX_WORKER_PROCESSES=8           # Default: 8, background worker processes (CPU cores)
#POSTGRES_MAX_PARALLEL_WORKERS_PER_GATHER=2 # Default: 2, workers per parallel query (1-4 typical)
#POSTGRES_MAX_PARALLEL_WORKERS=8           # Default: 8, total parallel workers (CPU cores)
#POSTGRES_MAX_PARALLEL_MAINTENANCE_WORKERS=2 # Default: 2, parallel maintenance workers (1-4 typical)

# Redis Performance Variables
# Memory management
#REDIS_MAXMEMORY=512mb                     # Default: 512MB, maximum memory usage (adjust based on queue size)
#REDIS_MAXMEMORY_POLICY=allkeys-lru        # Default: allkeys-lru, eviction policy when memory full
#                                          # Options: noeviction, allkeys-lru, allkeys-lfu, volatile-lru, volatile-lfu, volatile-random, volatile-ttl

# Network and connection settings
#REDIS_TCP_KEEPALIVE=300                   # Default: 300 seconds, TCP keepalive interval
#REDIS_TIMEOUT=0                           # Default: 0 (no timeout), client idle timeout in seconds
#REDIS_TCP_BACKLOG=511                     # Default: 511, TCP listen backlog size

# Database configuration
#REDIS_DATABASES=16                        # Default: 16, number of databases (0-15)

# Persistence settings (for queue durability)
#REDIS_SAVE_ENABLED=true                   # Default: true, enable RDB snapshots
#REDIS_SAVE_SECONDS=900                    # Default: 900 (15 min), snapshot if changes occur
#REDIS_SAVE_CHANGES=1                      # Default: 1, minimum changes to trigger snapshot
#REDIS_STOP_WRITES_ON_BGSAVE_ERROR=yes     # Default: yes, stop writes if background save fails
#REDIS_RDBCOMPRESSION=yes                  # Default: yes, compress RDB files
#REDIS_RDBCHECKSUM=yes                     # Default: yes, checksum RDB files

# Autoscaler Performance Variables
# Resource limits for the autoscaler container
#AUTOSCALER_CPU_LIMIT=0.5                  # Default: 0.5 cores, CPU limit for autoscaler
#AUTOSCALER_MEMORY_LIMIT=256m              # Default: 256MB, memory limit for autoscaler
#AUTOSCALER_LOG_LEVEL=INFO                 # Default: INFO, options: DEBUG, INFO, WARNING, ERROR

# Connection and timeout settings
#AUTOSCALER_REDIS_POOL_SIZE=10             # Default: 10, Redis connection pool size
#AUTOSCALER_REDIS_TIMEOUT=30               # Default: 30 seconds, Redis operation timeout
#AUTOSCALER_DOCKER_TIMEOUT=60              # Default: 60 seconds, Docker API operation timeout
#AUTOSCALER_QUEUE_CHECK_BATCH_SIZE=100     # Default: 100, batch size for queue length checks

# Monitor Performance Variables
# Resource limits for the monitoring container
#MONITOR_LOG_LEVEL=INFO                    # Default: INFO, options: DEBUG, INFO, WARNING, ERROR
#MONITOR_REDIS_TIMEOUT=10                  # Default: 10 seconds, Redis operation timeout
#MONITOR_METRICS_INTERVAL=30               # Default: 30 seconds, metrics collection interval
#MONITOR_MEMORY_LIMIT=128m                 # Default: 128MB, memory limit for monitor

## Autoscaling Tuning Guidelines
# 
# For light workloads (< 100 workflows/hour):
# - MIN_REPLICAS=1, MAX_REPLICAS=3
# - SCALE_UP_QUEUE_THRESHOLD=3, SCALE_DOWN_QUEUE_THRESHOLD=0
# - POLLING_INTERVAL_SECONDS=30, COOLDOWN_PERIOD_SECONDS=60
#
# For medium workloads (100-1000 workflows/hour):
# - MIN_REPLICAS=2, MAX_REPLICAS=5 (current defaults)
# - SCALE_UP_QUEUE_THRESHOLD=5, SCALE_DOWN_QUEUE_THRESHOLD=1 (current defaults)
# - POLLING_INTERVAL_SECONDS=10, COOLDOWN_PERIOD_SECONDS=10 (current defaults)
#
# For heavy workloads (> 1000 workflows/hour):
# - MIN_REPLICAS=3, MAX_REPLICAS=10
# - SCALE_UP_QUEUE_THRESHOLD=10, SCALE_DOWN_QUEUE_THRESHOLD=2
# - POLLING_INTERVAL_SECONDS=5, COOLDOWN_PERIOD_SECONDS=30
# - Consider increasing N8N_CONCURRENCY_PRODUCTION_LIMIT to 15-20
#
# Important: Always set N8N_GRACEFUL_SHUTDOWN_TIMEOUT higher than your longest workflow execution time

# Setup completion flag (set by setup.sh)
#SETUP_COMPLETED=false
